Bootstrap: docker
From: pytorch/pytorch:2.6.0-cuda12.4-cudnn9-devel

%environment
    export SSL_CERT_FILE=/etc/ssl/certs/ca-certificates.crt
    export PROJECT_DIR=/proj/berzelius-2024-336/users/x_bjabj
    export HF_HOME=$PROJECT_DIR/.hf
    export TRANSFORMERS_CACHE=$PROJECT_DIR/.cache/huggingface/transformers
    export HF_DATASETS_CACHE=$PROJECT_DIR/.cache/huggingface/datasets

%files
    pyproject.toml
    src/

%post
    # nano uses ripgrep and git so we ensure they are installed
    apt-get update
    apt-get install -y --no-install-recommends git curl ca-certificates ripgrep

    # Install base dependencies and vLLM
    # Use --find-links to avoid reinstalling pre-installed PyTorch/CUDA packages  
    pip install --find-links /opt/conda/lib/python3.11/site-packages ".[dev,vllm]"
    
    # Create script to install flash-attn with GPU at runtime
    cat > /usr/local/bin/install-flash-attn << 'EOF'
#!/bin/bash
echo "Installing flash-attn with GPU support..."
pip install flash-attn>=2.6.0 --no-build-isolation --force-reinstall
pip install flashinfer-python>=0.2.5 --force-reinstall
echo "Flash-attn installation complete"
EOF
    chmod +x /usr/local/bin/install-flash-attn

%runscript
    # Execute the command passed to the container
    exec "$@"