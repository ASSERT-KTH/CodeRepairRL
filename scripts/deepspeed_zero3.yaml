compute_environment: LOCAL_MACHINE # Specifies the environment. LOCAL_MACHINE means it's running on a single node/server (or potentially multiple nodes managed externally, like by SLURM).
debug: false                     # Disables extra verbose logging from DeepSpeed. Set to true for troubleshooting.
deepspeed_config:                # Section for DeepSpeed-specific parameters.
  deepspeed_multinode_launcher: standard # How to launch processes across nodes (if num_machines > 1). 'standard' often relies on MPI or SLURM.
  offload_optimizer_device: none # Where to offload optimizer states ('cpu', 'nvme', 'none'). 'none' keeps them on the GPU (if they fit).
  offload_param_device: none     # Where to offload model parameters ('cpu', 'nvme', 'none'). Relevant mainly for ZeRO-3. 'none' keeps them partitioned across GPUs.
  zero3_init_flag: true          # Enables efficient model initialization for ZeRO-3. Each GPU only materializes its partition of the model initially, saving memory during setup.
  zero3_save_16bit_model: true   # When saving a model checkpoint under ZeRO-3, gather the full parameters and save them in 16-bit precision (matching mixed_precision setting).
  zero_stage: 3                  # Specifies the ZeRO optimization stage (0, 1, 2, or 3). Stage 3 provides the maximum memory savings by partitioning parameters, gradients, and optimizer states.
distributed_type: DEEPSPEED      # Tells Accelerate to use DeepSpeed for distributed training.
downcast_bf16: 'no'              # Whether to automatically downcast data types to BF16 during communication (usually 'no' is fine).
machine_rank: 0                  # The rank of the current machine in a multi-node setup (starts from 0). For single-node training, this is always 0.
main_training_function: main     # The name of the function in your Python script that Accelerate should execute (usually 'main').
mixed_precision: bf16            # The type of mixed precision to use ('no', 'fp16', 'bf16'). BF16 is generally preferred on newer GPUs (Ampere+) for stability.
num_machines: 1                  # The total number of machines (nodes) being used for this training job.
num_processes: 8                 # The total number of processes (typically GPUs) across all machines. *Note: This value in the file is often overridden by the `--num_processes` flag passed to `accelerate launch` in your job scripts.*
rdzv_backend: static             # Rendezvous backend for coordinating processes. 'static' typically uses environment variables or a predefined address.
same_network: true               # Optimization hint: assumes all machines are on the same high-speed network.
tpu_env: []                      # Settings specific to Google TPUs (not applicable here).
tpu_use_cluster: false           # Settings specific to Google TPUs.
tpu_use_sudo: false              # Settings specific to Google TPUs.
use_cpu: false                   # Tells Accelerate not to force operations onto the CPU (essential for GPU training).