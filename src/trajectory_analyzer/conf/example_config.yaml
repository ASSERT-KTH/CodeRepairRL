# Example Trajectory Analyzer Configuration
# 
# This example uses paths from the CodeRepairRL-results and R2E-Gym repositories.
# Adjust paths as needed for your setup.
#
# Usage:
#   uv run python -m src.trajectory_analyzer --config-path conf --config-name example_config

output_dir: "./plots/trajectory_analysis"

plots:
  # Per-run plots (generated for each run):
  - tool_distribution          # Bar chart of tool usage counts
  - shell_command_distribution # Bar chart of shell commands (grep, cat, etc.)
  - success_rates              # Resolution rates, tool success rates
  - token_analysis             # Token usage analysis
  - error_patterns             # Top error messages (raw first 5 words)
  - failed_tool_calls          # Most common failing tool calls with arguments
  # Multi-run plots (when 2+ runs):
  - comparison                 # Cross-run comparison grid
  - transfer_analysis          # Transfer learning impact (basic summary)
  - transfer_mcnemar           # Instance-level transfer (McNemar contingency + stats)
  - transfer_error_modes       # Error mode comparison between scaffolds
  - transfer_vocabulary        # Tool vocabulary alignment and hallucinations
  - transfer_error_patterns    # Raw error message pattern changes

# Model to trained scaffold mapping
# DeepSWE was trained on R2E-Gym scaffold
model_to_trained_scaffold:
  "agentica-org/DeepSWE-Preview": "r2e-gym"

runs:
  # DeepSWE on nano-agent scaffold
  - name: "deepswe-nano-agent"
    format: "nano_agent"
    trajectories: "/home/andre/Repos/CodeRepairRL-results/nano-agent-agentica-org_DeepSWE-Preview/detailed_predictions.jsonl"
    results: "/home/andre/Repos/CodeRepairRL-results/nano-agent-agentica-org_DeepSWE-Preview/nano-agent-hosted_vllm__agentica-org__DeepSWE-Preview.deepswe_32b__nano__500_tool_cals.json"
    base_model: "agentica-org/DeepSWE-Preview"
    scaffold: "nano-agent"
    lora_adapter: null

  # DeepSWE on R2E-Gym scaffold (its training scaffold)
  - name: "deepswe-r2e-gym"
    format: "r2e_gym"
    trajectories: "/home/andre/Repos/CodeRepairRL-results/traj_deepswe32b/deepswe_32b_agent_swebv_eval_temp_1_run_3.jsonl"
    results: "/home/andre/Repos/CodeRepairRL-results/traj_deepswe32b/deepswe_32b_agent_swebv_eval_temp_1_run_3.deepswe_32b__r2egym__run3.json"
    base_model: "agentica-org/DeepSWE-Preview"
    scaffold: "r2e-gym"
    lora_adapter: null

  # Qwen base model on nano-agent
  - name: "qwen32b-nano-agent"
    format: "nano_agent"
    trajectories: "/home/andre/Repos/CodeRepairRL-results/nano-agent-Qwen_Qwen3-32B/detailed_predictions.jsonl"
    results: "/home/andre/Repos/CodeRepairRL-results/nano-agent-Qwen_Qwen3-32B/nano-agent-hosted_vllm__Qwen__Qwen3-32B.qwen_32b__nano__500_tool_calls.json"
    base_model: "Qwen/Qwen3-32B"
    scaffold: "nano-agent"
    lora_adapter: null

  # Qwen base model on R2E-Gym scaffold
  - name: "qwen32b-r2e-gym"
    format: "r2e_gym"
    trajectories: "/home/andre/Repos/CodeRepairRL-results/traj_qwen32b/qwen3_32b_agent_swebv_eval_temp_1_run_3.jsonl"
    results: "/home/andre/Repos/CodeRepairRL-results/traj_qwen32b/qwen3_32b_agent_swebv_eval_temp_1_run_3.qwen_32b__r2egym__run3.json"
    base_model: "Qwen/Qwen3-32B"
    scaffold: "r2e-gym"
    lora_adapter: null

hydra:
  job:
    chdir: false

