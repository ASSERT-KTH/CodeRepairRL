defaults:
  - single_turn

vllm_mode: "async_server"
multi_turn: true
mask_tool_responses: true

max_prompt_length: 1024  # not strictly enforced
max_completion_length: 7168  # but dr_grpo uses this for normalization

# we must fit an entire group per forward pass (per_device_train_batch_size * num_gpus % num_generations == 0)
num_generations: 4  # group size of GRPO
generation_batch_size: 8  # but our VLLM server can handle 8
per_device_train_batch_size: 4 
gradient_accumulation_steps: 2  # Accumulate gradients over 2 groups / batches

loss_type: "dr_grpo"

gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: true