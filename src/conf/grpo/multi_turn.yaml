defaults:
  - single_turn

vllm_mode: "async_server"
multi_turn: true
mask_tool_responses: true

max_prompt_length: 1024  # not strictly enforced
max_completion_length: 7168  # but dr_grpo uses this for normalization

num_generations: 4  # group size of GRPO
per_device_train_batch_size: 4  # we can fit one group per device
gradient_accumulation_steps: 2  # do that 2 times
generation_batch_size: 8  # and thus we need 8 roll-outs (inference side is way less computationally expensive, could do more but it is a trade-off)

loss_type: "dr_grpo"

gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: true