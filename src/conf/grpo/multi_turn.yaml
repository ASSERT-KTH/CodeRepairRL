defaults:
  - single_turn

vllm_mode: "async_server"
multi_turn: true
mask_tool_responses: true

max_prompt_length: 1024
max_completion_length: 7168

num_generations: 4  # group size of GRPO
per_device_train_batch_size: 4  # we can fit one group per device
gradient_accumulation_steps: 4  # do that 4 times
generation_batch_size: 16  # and thus we need 16 roll-outs (inference side is way less computationally expensive)

loss_type: "dr_grpo"

gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: true
