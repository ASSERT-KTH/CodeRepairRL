defaults:
  - short

per_device_train_batch_size: 4
gradient_accumulation_steps: 1
num_generations: 4
max_prompt_length: 1024  # not strictly enforced
max_completion_length: 7168  # but dr_grpo uses this for normalization

loss_type: "dr_grpo"

gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: true
