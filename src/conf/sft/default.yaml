# TrainingArguments parameters
output_dir: "outputs/sft_model"

num_train_epochs: 3
per_device_train_batch_size: 2
gradient_accumulation_steps: 8

learning_rate: 1e-4  # default value is for lora
warmup_ratio: 0.1
lr_scheduler_type: "cosine"
max_grad_norm: 0.5 
weight_decay: 0.01

# Model settings
bf16: true
fp16: false
gradient_checkpointing: true

# Logging
logging_steps: 10
save_steps: 500
eval_steps: 500
report_to: "wandb"
run_name: "${run.name}"

max_length: 16384
packing: true  # pack two shorter rollouts into one to match a longer, max_length rollout

assistant_only_loss: false  # ideally this would be true, but Qwen3's chat template does not support it